{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Alpha in 10-Ks and 10-Qs (Alphalens Study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THESIS:\n",
    "Major text changes in 10-K and 10-Q filings over time indicate significant decreases in future returns. We find alpha in shorting the companies with the largest text changes in their filings and buying the companies with the smallest text changes in their filings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publicly listed companies in the U.S. are required by law to file \"10-K\" and \"10-Q\" reports with the [Securities and Exchange Commission](https://www.sec.gov/) (SEC). These reports provide both qualitative and quantitative descriptions of the company's performance, from revenue numbers to qualitative risk factors.\n",
    "\n",
    "When companies file 10-Ks and 10-Qs, they are required to disclose certain pieces of information. For example, companies are required to report information about [\"significant pending lawsuits or other legal proceedings\"](https://www.sec.gov/fast-answers/answersreada10khtm.html). As such, 10-Ks and 10-Qs often hold valuable insights into a company's performance.\n",
    "\n",
    "These insights, however, can be difficult to access. The average 10-K was [42,000 words long](https://www.wsj.com/articles/the-109-894-word-annual-report-1433203762) in 2013; put in perspective, that's roughly one-fifth of the length of Moby-Dick. Beyond the sheer length, dense language and lots of boilerplate can further obfuscate true meaning for many investors.\n",
    "\n",
    "The good news? We might not need to read companies' 10-Ks and 10-Qs from cover-to-cover in order derive value from the information they contain. Specifically, Lauren Cohen, Christopher Malloy and Quoc Nguyen argue in their [recent paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1658471) that we can simply analyze textual changes in 10-Ks and 10-Qs to predict companies' future stock returns. For an overview of this paper from one of the authors, see the [Lazy Prices interview](https://www.youtube.com/watch?v=g96gROyc3wE) from QuantCon 2018.\n",
    "\n",
    "*To understand how the dataset used in this post was created, be sure to see the [Data Processing notebook](https://www.quantopian.com/posts/scraping-10-ks-and-10-qs-for-alpha).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.pipeline.filters import QTradableStocksUS\n",
    "import alphalens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data from Self-Serve Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we import the data from a local .csv file via the [Self-Serve Data](https://www.quantopian.com/posts/upload-your-custom-datasets-and-signals-with-self-serve-data) feature. \n",
    "\n",
    "To do this, we begin with the local .csv file generated by the [Data Processing notebook](https://www.quantopian.com/posts/scraping-10-ks-and-10-qs-for-alpha). We then upload it under the Self-Serve Data tab on the [Account &gt; Data page](https://www.quantopian.com/account#data); this makes it available for import into a research notebook or pipeline.\n",
    "\n",
    "For more on importing data using Self-Serve, check out the examples in [this forum post](https://www.quantopian.com/posts/upload-your-custom-datasets-and-signals-with-self-serve-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.pipeline.data.user_5b102ae91141120040958556 import lazyprices3_90d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Formatting Factor Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we uploaded is in a tabular form, with one row per asset per day. However, Alphalens requires that we provide data in a specific format with specific labels. Fortunately, [Pipeline](https://www.quantopian.com/tutorials/pipeline) will do all the \"dirty work\" for us.\n",
    "\n",
    "In this step, we'll use Pipeline to put our data in a form that can be ingested by Alphalens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    \n",
    "    jaccard_score = lazyprices3_90d.jaccard_score.latest\n",
    "    cosine_score = lazyprices3_90d.cosine_score.latest\n",
    "    \n",
    "    screen = (QTradableStocksUS() & jaccard_score.notnull() & cosine_score.notnull())\n",
    "    \n",
    "    return Pipeline(columns={'jaccard_score': jaccard_score, 'cosine_score': cosine_score}, screen=screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = run_pipeline(make_pipeline(), '2013-01-01', '2018-05-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Pricing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since an alpha factor is supposed to *predict the returns* of an asset, we'll need to get records of the actual price of the asset in order to examine the performance of our alpha factor. In this step, we get pricing data for the assets in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of relevant assets\n",
    "assets = data.index.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pricing data for those assets\n",
    "pricing_end_date = '2018-08-01' # Pricing end date should be later so we can get forward returns\n",
    "prices = get_pricing(assets,\n",
    "                     start_date='2013-01-01',\n",
    "                     end_date=pricing_end_date,\n",
    "                     fields='open_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Alphalens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both our alpha factor and pricing datasets, we're ready to run our Alphalens study.\n",
    "\n",
    "Since we have both Jaccard and cosine similarity scores, we'll run two separate Alphalens tearsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Jaccard Similarity Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating a tearsheet, we'll use `get_clean_factor_and_forward_returns` to get our data in the correct format to be ingested by Alphalens.\n",
    "\n",
    "**Note on parameters:** \n",
    "\n",
    "The `periods` parameter in `get_clean_factor_and_forward_returns` allows us to set the periods over which we assess the performance of our alpha factor (in days). Here, we'll use longer periods, since political processes tend to be longer-term phenomena.\n",
    "\n",
    "The `quantiles` parameter allows us to set the number of bins into which we divide our assets based on their factor values. Since the original paper uses 5 quantiles to estimate portfolio performance, we'll also use 5 quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_factor = data[['jaccard_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shorter periods (1, 5, 10 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data_j1 = alphalens.utils.get_clean_factor_and_forward_returns(\n",
    "    jaccard_factor,\n",
    "    prices=prices,\n",
    "    quantiles=5,\n",
    "    periods =(1, 5, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalens.tears.create_full_tear_sheet(factor_data_j1, by_group=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Midrange periods (1, 2, 3 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data_j2 = alphalens.utils.get_clean_factor_and_forward_returns(\n",
    "    jaccard_factor,\n",
    "    prices=prices,\n",
    "    quantiles=5,\n",
    "    periods =(20, 40, 60),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalens.tears.create_full_tear_sheet(factor_data_j2, by_group=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest periods (1.5, 3, 4.5 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data_j3 = alphalens.utils.get_clean_factor_and_forward_returns(\n",
    "    jaccard_factor,\n",
    "    prices=prices,\n",
    "    quantiles=5,\n",
    "    periods =(30, 60, 90),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalens.tears.create_full_tear_sheet(factor_data_j3, by_group=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Cosine Similarity Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll put our cosine score factor through the same process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_factor = data[['cosine_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data_c1 = alphalens.utils.get_clean_factor_and_forward_returns(\n",
    "    cosine_factor,\n",
    "    prices=prices,\n",
    "    quantiles=5,\n",
    "    periods =(1, 5, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalens.tears.create_full_tear_sheet(factor_data_c1, by_group=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Midrange periods (1, 2, 3 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data_c2 = alphalens.utils.get_clean_factor_and_forward_returns(\n",
    "    cosine_factor,\n",
    "    prices=prices,\n",
    "    quantiles=5,\n",
    "    periods =(20, 40, 60),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalens.tears.create_full_tear_sheet(factor_data_c2, by_group=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest periods (1.5, 3, 4.5 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data_c3 = alphalens.utils.get_clean_factor_and_forward_returns(\n",
    "    cosine_factor,\n",
    "    prices=prices,\n",
    "    quantiles=5,\n",
    "    periods =(30, 60, 90),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalens.tears.create_full_tear_sheet(factor_data_c3, by_group=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A few notes about this tearsheet:  \n",
    "\n",
    "- In the \"Cumulative Return by Quantile\" plots, we want to see the top and bottom quantile \"fingers\" move across the plot without crossing. It looks like they're significantly different over all periods, indicating that our factor is doing a good job of separating high- and low-returning stocks.\n",
    "- In the \"IC Normal Dist Q-Q\" plots, we want to see an S-shaped curve that indicates a Normal distribution with fat tails (since high/low factor values are the stocks that we want to long/short). We do see reasonably S-shaped curves in the plots over all periods.\n",
    "- For our top and bottom quantile, the mean turnover looks reasonable -- hovering around roughly 30-40%, which is well within the contest guideline of 5-65%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare to the paper's findings? The original paper found a spread of 31 bps in excess return between the 1st and 5th quantile for the cosine similarity score over a three-month holding period, and a spread of 53 bps for the Jaccard similarity score.\n",
    "\n",
    "Keep in mind that the mean period wise return calculated by Alphalens is the *rate of return*. As such, it's difficult to compare the Alphalens result exactly with the original result. However, we do see a spread somewhere around 20-50 bps between quantiles (depending on the factor and period), so it seems like our results are generally in-line with the paper's findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step? Put it in an algorithm and see how it performs in real-world conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
